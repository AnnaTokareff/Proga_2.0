import os
import re
import gc
import glob
import json 
import nltk
import string
import pymorphy2
import pandas as pd  
import numpy as np
from nltk.corpus import stopwords 
from sklearn.cluster import DBSCAN, KMeans
from nltk.tokenize import sent_tokenize, word_tokenize
from sklearn.metrics import silhouette_score
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import matplotlib.pyplot as plt


s_words = set(stopwords.words('russian'))
s_words.update(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', 'к', 'на','по','у'])
morph = pymorphy2.MorphAnalyzer()

class summarizer:
    def __init__(self,text="",matrix=None,model=None,vec=None):
        self.train = None
        self.test = None
        self.valid= None
        self.vec = vec
        self.model = model
        self.sent = []
        self.text = text
        self.matrix = matrix
        self.elbow_data = {}


    def open_files(self):
    	with open("gazeta_train.jsonl","rb") as f2:
    		self.train=pd.read_json(f2,lines=True)
    		#gc.collect()
    	#with open("gazeta_test.jsonl","rb") as f1:
    		#self.test=pd.read_json(f1, lines=True)
    	with open("gazeta_train.jsonl","rb") as f3:
    		self.valid=pd.read_json(f3,lines=True)
	    		
    	return ("Я открыл файлы")

    def __repr__(self):
    	return (self.test.info(),self.train.info(),self.valid.info())

    
    def preprocess_text(self,text):

        ''' Предобработка текста, возвращает список предложений'''

        #text = text.lower()
        #text = re.sub(r"\d+", "", text)
        text = re.sub(r'[^\w\s\d\\.]','', text) 
        sent = [sent.strip() for sent in nltk.sent_tokenize(text)]
        self.sent = [sentence.replace("\n","") for sentence in sent]
        print("Обработка")
        return (self.sent)


    def fit_clustering(self):
        '''Обучение модели '''
        print("Я в функции fit_clustering")
        preprocess_text = self.preprocess_text
        vec= TfidfVectorizer(tokenizer=lambda x: preprocess_text(x))
        self.matrix = vec.fit_transform(self.train["text"].values)
        print("Векторизовал")
        model = KMeans(n_clusters=3,init="k-means++",random_state=42)
        model.fit(self.matrix)
        #self.train['label']= model.predict(self.matrix)
        #val_matrix = vec.transform(self.valid["text"].values)
        #self.valid["label"] = model.predict(val_matrix)
        labels = model.labels_
        cluster_centers=model.cluster_centers_
        centroids = model.cluster_centers_.argsort()[:, ::-1]
        close_words = vec.get_feature_names()
        for i in range(3):
            print("Cluster %d:" % i,end=""),
            for ind in centroids[i, :10]:
                print(' %s' % close_words[ind],end="")
                print()
        
        
    def elbow_method(self):
        '''Метод локтя для оптимального количества кластеров '''
        for k in range(2, 10):
            model = KMeans(n_clusters=k)
            labels = model.fit_predict(self.matrix)
            self.elbow_data[k] = np.sqrt(model.inertia_)
        
        plt.figure(figsize=(12,6))
        plt.plot(list(self.elbow_data.keys()), list(self.elbow_data.values()), 'bx-')
        plt.xlabel('Values of K')
        plt.ylabel('Inertia')
        plt.title('The Elbow Method using Inertia')
        plt.show()

    def  silhouette_coeff(self):
        '''Метрика силуэт для оптимального количества кластеров'''
        for k in range(2, 10):
            kmeans = KMeans(n_clusters=k).fit(self.matrix)
            label = kmeans.labels_
            sil_coeff = silhouette_score(self.matrix, label, metric='euclidean')
            print("For n_clusters={}, The Silhouette Coefficient is {}".format(k, sil_coeff))
    

    def main(sef,text):
        X = self.vec.fit_transform(result)
        self.model.predict(X)
        centroids = self.model.cluster_centers_.argsort()[:, ::-1]
        close_words = self.vec.get_feature_names()
        for i in range(true_k):
            print("Cluster %d:" % i),
        for ind in centroids[i, :10]:
            print(' %s' % close_words[ind]),
            

    #if __name__ == "__main__":
       # main()        










reader = summarizer()
reader.open_files()
#reader.__repr__()
#reader.preprocess_text()
reader.fit_clustering()
#reader.silhouette_coeff()
#reader.elbow_method()
